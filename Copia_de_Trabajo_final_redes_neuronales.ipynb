{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElAruspice/proyecto_sapiencia/blob/main/Copia_de_Trabajo_final_redes_neuronales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysu802rM00Hd"
      },
      "source": [
        "<div align=\"left\">\n",
        "<p><img alt=\"Sapiencia\" height=\"140px\" src=\"https://ubicua.ingeniaudea.co/pluginfile.php/32974/coursecat/description/RF_RedesNeuronales.png\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p></div>\n",
        "<div align=\"left\"></div>\n",
        "<div>\n",
        "\n",
        "<br></br>\n",
        "\n",
        "<div align=\"left\">\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "\n",
        "\n",
        "<hr size=10 noshade color=\"#663398\">\n",
        "</p>\n",
        "\n",
        "<div align=\"right\">\n",
        "<h1> <b> Trabajo final redes neuronales </b> </h1>\n",
        "<br>\n",
        "\n",
        "\n",
        "**El presente material hace parte de la ruta de formación del talento especializado de SAPIENCIA**\n",
        "\n",
        "**Los documentos que utilizaremos en la presente y proximas clases son una mezcla del trabajo de muchos profesores y académicos.**\n",
        "\n",
        "**En caso de utilizar el presente contenido favor citarlo y brindar los créditos respectivos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRqXII5-G3fA"
      },
      "source": [
        "\n",
        "**Integrantes**\n",
        "\n",
        "Jhon Esteban Velásquez Gómez<br>\n",
        "Geiver Alberto Zabala Lopera<br>\n",
        "Alberto Náder Galeano<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtUNRiakL2zY"
      },
      "source": [
        "**Descripción trabajo final**\n",
        "\n",
        "<p>\n",
        "  1. Analizar el código paso a paso y entenderlo y realizar una breve explicación de como funciona.<br>\n",
        "  2. Realizar módificaciones variando parámetros como la cantidad de neuronas, tipo de optimizador, funciones de activación, funciones de pérdida y tamaños de entrada de la imagen.<br>\n",
        "  3. A partir del entendimiento del código en el punto 1 responda las siguientes preguntas: <br>\n",
        "  <ul>\n",
        "    <li> ¿Cual es el objetivo de categorizar los targets o labels correspondientes a cada imagen? </li>\n",
        "    <li> ¿En que me ayuda la normalización a la hora de entrenar los datos? </li>\n",
        "  </ul>\n",
        "  <p>\n",
        "  4. Realice un informe detallando los resultados obtenidos en el punto 2. El informe debe responder las siguiente preguntas:\n",
        "  <ul>\n",
        "    <li> ¿Cómo variaron los resultados con el aumento o disminución de las neuronas?</li>\n",
        "    <li> ¿Cómo cambia la presición del modelo propuesto, al cambiar la función de activación, que se logra observar de los resultados?</li>\n",
        "    <li> ¿Cuál sería a su criterio la función de activación que se adapta al presente análisis ?</li>\n",
        "    <li> ¿Cómo se comportaron los resultados de las funciones de perdidas analizadas?</li>\n",
        "    <li> ¿Mejoraron los resultados al reducir o aumentar el tamaño de entrada de la imagen?</li>\n",
        "    <li> ¿Cuál fue la mejor solución que logró encontrar y por qué?</li>\n",
        "\n",
        "  </ul>\n",
        "\n",
        "  Nota: El informe debe llevar los valores que probaron en el módelo y para lo cuál como mínimo se deben analizar 4 optimizadores, 4 funciones de activación, 4 funciones de pérdida, 4 opciones de neuronas y tamaños de entrada de la imagen.<br>\n",
        "<p>\n",
        "  5. Concluir en que casos se debe utilizar los optimizadores, funciones de perdida, funciones de activación y tener en cuenta que se debe presentar una gráfica representativa de cada función de activación describiendo los rangos de la función y su comportamiento.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqfHnoyvk2f"
      },
      "source": [
        "**Porcentajes de calificación:**\n",
        "\n",
        "\n",
        "1.   Punto 1 : 10%\n",
        "2.   Punto 2 : 10%\n",
        "3.   Punto 3 : 10%\n",
        "4.   Punto 4 : 25%\n",
        "5.   Punto 5 : 15%\n",
        "6.   Sustentación : 30%\n",
        "\n",
        "\n",
        "**Limitantes**\n",
        "   Grupos máximo de 3 personas y mínimo de 2 personas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVpTSK0uX6Vx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_dF_6RQK1Al"
      },
      "source": [
        "Para iniciar, se instalan las librerías requeridas para el ejercicio propuesto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgbIgNa42evs",
        "outputId": "ca29a9ee-d743-447a-98bd-c08965e67e6f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOKDrhs049Ti",
        "outputId": "c3443da3-e3c5-49c0-cc14-10403347979c"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoWLUAZyK4L0"
      },
      "source": [
        "Las bibliotecas TensorFlow y  Keras en Python son ampliamente utilizadas para el aprendizaje profundo. Mientras Tensorflow se encarga de ejecutar los gráficos de forma ágil, Keras facilita la creación de modelos de aprendizaje profundo en Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDOSj3865Syn"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras import layers, models\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC_B5rndLKd8"
      },
      "source": [
        "A continuación, se procede a instalar los módulos dentro de las bibliotecas mencionadas.\n",
        "\n",
        "**Import numpy as np →** Importa la biblioteca NumPy y la renombra con el alias \"np\", que se utiliza para el cálculo de operaciones numéricas eficientes.\n",
        "\n",
        "**From keras impor layers, models →** Importa módulos relacionados con la creación de modelos de aprendizaje profundo utilizando la librería Keras.\n",
        "\n",
        "\n",
        "**from keras.utils import to_categorical →** Importa una función que convierte etiquetas en one-hot enconding (un equivalente de un escalar en un vector para facilitar su manipulación). Ej. Al ingresar el número 3 se obtiene el siguiente vector:  [0,0,0,1,0,0,0,0,0,0]\n",
        "\n",
        "**Mnist** (Modified National Institute of Standards and Technology database): Contiene un conjunto de entrenamiento de 60.000 imágenes de dígitos manuscritos (de 0 a 9) y otro conjunto de pruebas con 10.000 muestras adicionales.\n",
        "\n",
        "**Matplotlib**: Biblioteca utilizada para crear gráficos y visualizaciones.\n",
        "\n",
        "**Pandas:** Biblioteca de código abierto utilizada en Python para cargar, alinear, manipular o incluso fusionar conjuntos de datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzDwuO3CLHRP"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "(train_data, train_labels), (test_data, test_labels) =mnist.load_data()\n",
        "# Aplana las imágenes y conviértelas en un DataFrame\n",
        "train_data_flattened = train_data.reshape(train_data.shape[0], -1)\n",
        "train_data_df = pd.DataFrame(train_data_flattened)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycaa2wu5LP5Z"
      },
      "source": [
        "**(train_data, train_labels), (test_data, test_labels) =mnist.load_data()**\n",
        "\n",
        "Esta línea de código, carga los datos de entrenamiento de acuerdo a la imagen a evaluar por medio de las variables train_data y train_label, así como los datos de prueba y aprendizaje por medio de las variables test_data y test_label. Esto permite entrenar y evaluar modelos de clasificación para el reconocimiento de dígitos ingresados mano a mano.\n",
        "\n",
        "\n",
        "**train_data_flattened = train_data.reshape(train_data.shape[0], -1)**\n",
        "\n",
        "Esta línea de código toma el conjunto de datos de entrenamiento train_data, que contiene imágenes tridimensionales y las convierte o aplana en una matriz bidimensional. La forma resultante de train_data_flattened será (60000, 28 * 28), lo que significa que se obtiene una matriz con 60000 filas (una por cada imagen) y 784 columnas (una por cada píxel en una imagen 28x28).\n",
        "\n",
        "\n",
        "**train_data_df = pd.DataFrame(train_data_flattened)**\n",
        "\n",
        "Convierte los datos de entrenamiento a un Dataframe utilizando la biblioteca Pandas. Un dataframe es una estructura de datos tabular que facilita la manipulación y el análisis de datos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ID-YTAHLNUm",
        "outputId": "8828a5f1-5c0f-4167-bbeb-94feb842f801"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1X4EXBYLSPq"
      },
      "source": [
        "En el momento de cargar el conjunto de datos **MNIST**, la variable **train_data** contendrá una matriz tridimensional que almacena las imágenes de los dígitos.\n",
        "\n",
        "La forma típica de esta matriz es (número de imágenes, altura de imagen, ancho de imagen). Se tiene 60,000 imágenes en el conjunto de entrenamiento y cada imagen es de 28x28 píxeles, train_data será una matriz con una forma de (60000, 28, 28):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "GXfjzxnzIuQA",
        "outputId": "3a4b3068-2091-4b79-8f8f-78ef25a73918"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "train_data_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMd68NNBLUVt"
      },
      "source": [
        "Se imprime por pantalla las 10 primeras filas del dataframe train_data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKLfyhekLgjN",
        "outputId": "3a2ca8d7-e734-4fa9-ecc9-996398803fa1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "train_data_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bexLDF8xLWUW"
      },
      "source": [
        "Trae la dimensión del dataframe train_data_df, la cual posee  60.000 filas y 784 columnas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp_iGtjvL2WD",
        "outputId": "d26dbd19-2966-4d72-d823-a256e897a6a7"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsW98AlULh7h"
      },
      "source": [
        "Trae la dimensión de la matriz train_data, donde tenemos una matriz con 60.000 imágenes, cada una tiene 28 filas y 28 columnas, cada uno de estos elementos va de 0 a 255 representando el color del pixel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eNLGX_RL6u-",
        "outputId": "c9d5f4f8-3e28-4ed3-9bbe-1dd02d18cbce"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "train_data_df[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4Bnz56SLZGl"
      },
      "source": [
        "Imprime la primera columna del dataframe train_data_df, la cual corresponde al primer píxel de cada imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNR2MEbzLksk",
        "outputId": "b388247c-ce94-401e-8b74-62c518f19fa2"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocIe4z48Lmk-"
      },
      "source": [
        "\n",
        "Imprime una matriz de dimensión 28 * 28, la cual representa la primera imagen del train_data ya que se seleccionó el primer elemento con [0]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "dMnGC9IbLq5k",
        "outputId": "be9e3563-96bf-4be7-a9d8-4f0049b9fb93"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "plt.imshow(train_data[689])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYcmhG_yLpAf"
      },
      "source": [
        "El alias **plt** se refiere a la biblioteca Matplotlib, que se utiliza para crear gráficos y visualizaciones en Python. train_data[689] accede a la imagen número 689 en el conjunto de datos de entrenamiento MNIST. La notación train_data[689] significa que estamos tomando la imagen número 689 de la matriz train_data. La función **imshow** toma esta imagen y la muestra en una ventana gráfica. Se puede verificar cómo se ve la imagen número 689 en el conjunto de datos. Esto es útil para la visualización y la inspección de datos cuando trabajas con conjuntos de datos de imágenes, como MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbNyjcXtMTMZ",
        "outputId": "ac9d48d9-ecbc-41d5-8d20-3e8b2f32f646"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "train_labels[689]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-NqeT-4LrDI"
      },
      "source": [
        "\n",
        "Imprime la etiqueta o valor al cual corresponde la imagen en la posición 689\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1NmNS5fMZIj"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512,activation='relu', input_shape=(28*28,)))\n",
        "model.add(layers.Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txmclE4uL1fC"
      },
      "source": [
        "Inicializa el modelo de red neuronal utilizando la biblioteca Keras. Se crean 2 capas de redes neuronales donde fluyen los datos en una sola dirección, ya que se definió un modelo secuencial.\n",
        "La primer capa tiene 28*28 neuronas de entrada y **512** neuronas de salida, esta tiene una función de activación **‘relu’**.\n",
        "La segunda capa tiene 10 neuronas de salida, de acuerdo con el rango en cada valor de 0 a 9. Por último esta capa utiliza la función de activación **‘softmax’**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il99HYMOMbI5"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', 'Precision'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srhNtdtEL4U7"
      },
      "source": [
        "**model.compile():** Este método compila el modelo antes de comenzar el proceso de entrenamiento, se le ingresan los siguientes parámetros:\n",
        "\n",
        "<li> optimizer='rmsprop': Se especifica el optimizador que se utilizará durante el entrenamiento. En este caso, se usa el optimizador 'rmsprop'. Los optimizadores son algoritmos que ajustan los pesos de la red durante el proceso de entrenamiento para minimizar la función de pérdida.</li>\n",
        "<p>\n",
        "<li> loss='categorical_crossentropy': Se especifica la función de pérdida que se utilizará para medir el rendimiento del modelo durante el entrenamiento. 'Categorical Crossentropy' es una función de pérdida comúnmente utilizada en problemas de clasificación multi-clase, como el reconocimiento de dígitos en MNIST.</li>\n",
        "<p>\n",
        "<li>metrics=['accuracy', 'Precision']: Se especifican las métricas que se utilizarán para evaluar el rendimiento del modelo. En este caso, se utiliza 'accuracy' (exactitud) y 'Precision' como métricas. 'Accuracy' mide la fracción de ejemplos clasificados correctamente, mientras que 'Precision' se refiere a la capacidad del modelo de no etiquetar incorrectamente una muestra como positiva.</li>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-SJPCjqMf2E",
        "outputId": "6f7f6d65-ad91-4728-aae8-edd8371f7ef2"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32ewc6zuL6HJ"
      },
      "source": [
        "Ofrece un resumen de la construcción de la red neuronal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0Ti2l0yMMT2"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "x_train = train_data_df\n",
        "#x_train = train_data.reshape((60000,28*28))\n",
        "x_train = x_train.astype('float32')/255\n",
        "\n",
        "x_test = test_data.reshape((10000,28*28))\n",
        "x_test = x_test.astype('float32')/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3gJ17y0L78U"
      },
      "source": [
        "**x_train = train_data_df** → Asigna los datos de entrenamiento que se habían almacenado previamente en un DataFrame llamado train_data_df a la variable x_train. Esto implica que x_train contiene las imágenes de entrenamiento aplanadas en formato DataFrame.\n",
        "\n",
        "**x_train = x_train.astype('float32')/255 →** Convierte los valores de pixeles en x_train al tipo de dato 'float32' para garantizar que sean números flotantes. Luego, divide cada valor de píxel por 255. Esta operación normaliza los valores de pixeles a un rango entre 0 y 1, ya que en imágenes, los pixeles suelen tener valores en el rango de 0 a 255.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEFqGFolMAvU"
      },
      "source": [
        "\n",
        "Por consiguiente, el ***test_data*** se “reorganiza” o remodela por medio del método **reshape**, transformando en un conjunto de datos de tipo float. Luego se divide cada valor x_test por 255, representando una escala en la cual 0 es la oscuridad máxima y 255 la mayor intensidad en la imagen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4cmdNlxMrkc",
        "outputId": "93c159b0-920c-41cd-fd83-f04dd76f275e"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o13nlxFMCg-"
      },
      "source": [
        "Imprime los datos normalizados en la columna 1 del dataframe x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph1tcO85MtaD"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "y_train = to_categorical(train_labels)\n",
        "y_test =to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Mrc3PRMFFM"
      },
      "source": [
        "**y_train = to_categorical(train_labels) →** Convierte las etiquetas de clase del conjunto de datos de entrenamiento (**train_labels**) en formato \"one-hot encoding\". En MNIST, hay 10 clases correspondientes a los dígitos del 0 al 9. El *one-hot encoding* convierte estas etiquetas en vectores binarios, donde un 1 se coloca en la posición correspondiente a la clase y todas las demás posiciones se establecen en 0. Por ejemplo, si una imagen contiene el dígito \"3\", la etiqueta se convierte en [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].\n",
        "\n",
        "**y_test** = to_categorical(test_labels): Realiza la misma conversión para las etiquetas de clase del conjunto de datos de prueba (test_labels).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at6f6n_MMynk",
        "outputId": "0d866906-130b-4577-95ee-a9333d818fac"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "train_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-buzMW2ZMGzu"
      },
      "source": [
        "Imprime el valor de la etiqueta para la imagen en la posición 0, este imprime 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNq-PACkM5Jz",
        "outputId": "c641a424-4c76-4656-f969-569059777a36"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osC-R5FCMIal"
      },
      "source": [
        "imprime la posición en formato _“one-hot encoding”_ de acuerdo a la categoría establecida en el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFDP3PNIM-ba",
        "outputId": "220ecdf5-38b8-4af2-a0ed-41e643d56761"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFihiD-AMKtR"
      },
      "source": [
        "**history = model.fit() →** Inicia el proceso de entrenamiento del modelo y guarda la información relacionada con el proceso de entrenamiento en un objeto llamado history.\n",
        "\n",
        "**x_train y y_train →** Los datos de entrenamiento (x_train) y las etiquetas de clase correspondientes (y_train) se utilizan para entrenar el modelo. x_train contiene las imágenes de entrenamiento preprocesadas y y_train contiene las etiquetas de clase en formato \"one-hot encoding\".\n",
        "\n",
        "**Epochs=10 →** Establece el número de épocas de entrenamiento. Una época es una pasada completa a través de todo el conjunto de datos de entrenamiento. En otras palabras, es el número de iteraciones transcurridas entre los datos.\n",
        "En este caso, se entrena el modelo durante 10 épocas, lo que significa que pasará 10 veces por el conjunto de entrenamiento para ajustar los pesos de la red.\n",
        "\n",
        "**batch_size=128 →** Establece el tamaño del lote (batch size) para el entrenamiento. Durante el entrenamiento, el modelo no ajusta los pesos con cada muestra individual, sino con lotes de muestras. En este caso, se utilizan lotes de 128 muestras a la vez.\n",
        "\n",
        "**validation_data=(x_test, y_test) →** Utiliza los datos de prueba (x_test y y_test) como datos de validación para evaluar el rendimiento del modelo durante el entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "6o_zWTPlG-c_",
        "outputId": "c12121be-3db3-4c84-b7f1-0b76f7456018"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "pd.DataFrame({'loss': history.history['loss'],\n",
        "              'val_loss': history.history['val_loss']}).plot(figsize=(10, 7))\n",
        "\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUjGZKYbMNVn"
      },
      "source": [
        "Se crea un Dataframe de la biblioteca Pandas. En éste, se aloja un Diccionario de dos campos clave-valor.  La clave **“loss”** se asigna a los valores de pérdida en el conjunto de entrenamiento, y la clave \"**val_loss**\" se asigna a los valores de pérdida en el conjunto de validación. Estas columnas, se llenan con los valores de pérdida registrados durante el entrenamiento y la validación, respectivamente. Al final, se usa **“plot”** para trazar las curvas de las pérdidas en el entrenamiento, estableciendo un tamaño de 10 unidades de ancho por 7 de alto.\n",
        "\n",
        "Esto es útil para evaluar el rendimiento del modelo en datos no vistos y para identificar si el modelo está sobre-ajustado o sub-ajustado. Si la pérdida de validación disminuye a medida que avanzan las épocas, el modelo está aprendiendo correctamente. Si la pérdida de validación aumenta o se estabiliza, podría ser un indicio de que el modelo no está generalizando bien y necesita ajustes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P10S3C_ZMP02"
      },
      "source": [
        "Mediante la librería Matplotlib se traza una cuadrícula en el gráfico ya interpuesto.\n",
        "\n",
        "**plt.grid(True) →** Activa la cuadrícula en el gráfico, agregando los parámetros del eje X y el eje Y en un plano, facilitando la lectura de los valores en el gráfico así como la posición de los puntos o las curvas con mayor precisión.\n",
        "\n",
        "**plt.xlabel(“epochs”) →**. Establece una etiqueta del eje X en el gráfico. En este caso, la etiqueta es “epochs”, lo que indica que el eje X representa las épocas en el contexto del entrenamiento del aprendizaje automático.\n",
        "\n",
        "**plt.show()→** muestra el gráfico en pantalla.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQVdu9blNLk8",
        "outputId": "3203f619-8f67-4b7f-adf0-a91132bde34b"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/alber/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkvnNH23MVYb"
      },
      "source": [
        "En este caso, la pérdida es 0.0670 y la precisión es 0.9813, lo que significa, que el modelo clasifica correctamente aproximadamente el 98.13% de las muestras en el conjunto de prueba.\n",
        "\n",
        "El valor de la métrica de precisión en el conjunto de datos de prueba. En este caso, la precisión es 0.9827.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXX2faJQTY1v"
      },
      "source": [
        " <H4>3. A partir del entendimiento del código en el punto 1 responda las siguientes preguntas:</h4>\n",
        " \n",
        "<li> ¿Cual es el objetivo de categorizar los targets o labels correspondientes a cada imagen? </li>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZJEFUKET0SR"
      },
      "source": [
        "**R/**\n",
        "\n",
        "El objetivo de categorizar los \"targets\" o etiquetas correspondientes a cada imagen en un problema de machine learning o deed learning, especialmente en problemas de clasificación, es permitir que el modelo aprenda a realizar predicciones precisas y asignar cada entrada (en este caso, una imagen) a una de las categorías predefinidas.(en este caso, número entre 0 y 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_O71BxqTz7e"
      },
      "source": [
        "\n",
        "<li> ¿En que me ayuda la normalización a la hora de entrenar los datos? </li>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXmsa7d7TzuQ"
      },
      "source": [
        "**R/**\n",
        "\n",
        "La normalización es una técnica crucial en el preprocesamiento de datos antes de entrenar una red neuronal y ofrece varios beneficios fundamentales para el proceso de entrenamiento. Entre sus beneficios, se encuentran los siguientes:\n",
        "\n",
        "- La normalización de los datos suele hacer que el proceso de entrenamiento converja más rápido. Cuando los datos de entrada tienen una escala más consistente, los gradientes durante la retropropagación son más estables y, por lo tanto, el modelo converge a una solución más rápidamente.\n",
        "\n",
        "- Ayuda a mitigar problemas numéricos al escalar los datos de manera que todos tengan una margen similar (por ejemplo, entre 0 y 1 o con una media cero y desviación estándar uno)  manteniendo los valores dentro de rangos más manejables. Esto también beneficia a mejorar la capacidad del modelo de generalizar a datos no vistos\n",
        "\n",
        "- Puede hacer que el entrenamiento de redes profundas sea más estable y menos propenso a oscilaciones o comportamientos indeseados."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
